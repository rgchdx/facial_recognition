import os
import cv2
import pickle
import face_recognition
import numpy as np
import cvzone
from supabase import create_client, Client
from dotenv import load_dotenv
import os

load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

### Webcam setup ###
cap = cv2.VideoCapture(0)  # If using multiple cameras, change 0 to 1
cap.set(3, 680)  # Set width slightly smaller than 720
cap.set(4, 510)  # Set height slightly smaller than 540

imgBackground = cv2.imread("Resources/background.png")

###Importing the mode images into a list###
folderModePath = 'Resources/Modes'
modePathList = os.listdir(folderModePath) #obtain all of the files in the folder and put it in a list
imgModeList = [] #create empty list to store all the images
for path in modePathList: #iterate through the list of files
    imgModeList.append(cv2.imread(os.path.join(folderModePath,path))) #we use cv2 to read the images and appepend it to the list. Use os.path.join to get the full path of the image
#print(len(imgModeList))

# load the encoding file
print('Loading Encode File...')
file = open('EncodeFile.p', 'rb')  # open a file in read binary mode (unpickling)
encodeListKnownWithIds = pickle.load(file)
file.close()
encodeListKnown, faceIds = encodeListKnownWithIds
print(faceIds)
print('Encode File Loaded')
modeType = 3
# 3 is active mode
# 0 is showing info mode
# 1 is showing attendance mode
# 2 is showing already attended mode
counter = 0 
id = -1
read = False

### What the webcam will show ###
while True:
    success, img = cap.read()
    
    # Resize the webcam feed to match the new dimensions
    img_resized = cv2.resize(img, (680, 510))  
    mode_img_height, mode_img_width = imgModeList[0].shape[:2]
    mode_img_resized = cv2.resize(imgModeList[modeType], (470, 700))
    
    imgS = cv2.resize(img_resized, (0, 0), None, 0.25, 0.25) 
    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)
    
    faceCurrentFrame = face_recognition.face_locations(imgS) # find the face locations in the current frame
    # Get the location of the face, extract it and encode it
    encodeCurrentFrame = face_recognition.face_encodings(imgS, faceCurrentFrame)
    
    
    # Place the resized webcam feed in the background
    imgBackground[175:175+510, 60:60+680] = img_resized  # Adjusted placement
    imgBackground[50:50+700, 855:855+470] = mode_img_resized
    
    for encodeFace, faceLoc in zip(encodeCurrentFrame, faceCurrentFrame):
        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)  # Compare the current frame's encoding with the known encodings
        # lower the distance better the match
        faceDistance = face_recognition.face_distance(encodeListKnown, encodeFace)  # Calculate the distance between the current frame's encoding and the known encodings
        # print("matches:", matches)
        # print("faceDistance:", faceDistance)
        # each value generated by matches corresponds to each of the images that we have stored as in the list.
        # lower the value, better the match
        matchIndex = np.argmin(faceDistance) # find the index of the minimum value in the faceDistance array
        # print("matchIndex:", matchIndex)
        if matches[matchIndex]:
            # print("Known Face Detected")
            # print("Face ID:", faceIds[matchIndex])
            y1, x2, y2, x1 = faceLoc  # Unpack the face location
            y1, x2, y2, x1 = y1*4, x2*4, y2*4, x1*4  # Scale the face location back to the original size
            bbox = 50+x1, 175+y1, x2-x1, y2-y1  # Create a bounding box for the face 
            imageBackground = cvzone.cornerRect(imgBackground, bbox, rt=0)
            id = faceIds[matchIndex] # Get the ID of the matched face
            if not read:
                read = True
                
    ### FIND A WAY TO GET THE FACE ID FROM THE DATABASE ONCE!!! ###
    if read:
        id = supabase.table("sensor_data").select("id").eq("id", id).execute()
        print(id)
            

    cv2.imshow("Webcam", img_resized)
    cv2.imshow("Face Attendance", imgBackground)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit
        break

cap.release()
cv2.destroyAllWindows()